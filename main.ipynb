{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def convert_speech_to_audio_buffer(phrase:str, target_array:List[bytes]):\n",
    "    wf = tts.tts(\n",
    "        text = phrase,\n",
    "        language = 'en',\n",
    "        speaker_wav = 'hagrid_speech.wav',\n",
    "        split_sentences = False,\n",
    "        speed = 2.0,\n",
    "    )\n",
    "    buf = np.asarray(wf, dtype=np.float32) * 0.1\n",
    "    target_array.append(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "model_id = 'hagrid'\n",
    "try:\n",
    "    ollama.delete(model_id)\n",
    "except Exception:\n",
    "    pass\n",
    "ollama.create(model_id, path=f\"{model_id}.modelfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import threading\n",
    "import time\n",
    "import ollama\n",
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "OUT_STREAM = p.open(rate=23500, channels=1, format=pyaudio.paFloat32, output=True)\n",
    "\n",
    "sentence_end_pattern = re.compile(r'[!\\?\\.]')\n",
    "action_pattern = re.compile(r'\\*[\\s\\w\\d\\-]+\\*')\n",
    "\n",
    "context = []\n",
    "while True:\n",
    "    prompt = input('>> ')\n",
    "    if len(prompt) == 0:\n",
    "        break\n",
    "    context.extend([{'role':'user', 'content':prompt}])\n",
    "    while len(context) > 8:\n",
    "        del context[0]\n",
    "\n",
    "    OUT_STREAM.stop_stream()\n",
    "    phrase = []\n",
    "    full_resp = []\n",
    "    threads = []\n",
    "    target_array = []\n",
    "    for resp in ollama.chat(model=model_id, messages=context, stream=True):\n",
    "        token = resp['message']['content']\n",
    "        phrase.append(token)\n",
    "        if sentence_end_pattern.search(token):\n",
    "            speech = ''.join(phrase)\n",
    "            speech_cleaned = action_pattern.sub('', speech)\n",
    "            t = threading.Thread(target=convert_speech_to_audio_buffer, name='background_tts', kwargs={'phrase':speech, 'target_array':target_array})\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "            full_resp.extend(phrase)\n",
    "            phrase = []\n",
    "\n",
    "    OUT_STREAM.start_stream()\n",
    "    for bytes_val in target_array:\n",
    "        OUT_STREAM.write(bytes_val)\n",
    "    \n",
    "    response = ''.join(full_resp)\n",
    "    context.extend([{'role':'assistant', 'content':response}])\n",
    "    \n",
    "    print('---')\n",
    "    print(prompt)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-animatronics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
